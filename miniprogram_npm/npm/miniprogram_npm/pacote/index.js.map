{"version":3,"sources":["index.js","fetcher.js","util/is-package-bin.js","util/trailing-slashes.js","util/cache-dir.js","git.js","file.js","remote.js","../package.json","dir.js","util/tar-create-options.js","util/npm.js","util/add-git-sha.js","registry.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AIZA,AFMA,ACHA;AFOA,ADGA,AIZA,AFMA,ACHA;AFOA,ADGA,AIZA,AFMA,ACHA;AFOA,AIZA,ALeA,AIZA,AFMA,ACHA;AFOA,AIZA,ALeA,AIZA,AFMA,ACHA;AFOA,AIZA,ALeA,AIZA,AFMA,ACHA;AFOA,AKfA,ADGA,ALeA,AIZA,AFMA,ACHA;AFOA,AKfA,ADGA,ALeA,AIZA,AFMA,ACHA;AFOA,AKfA,ADGA,ALeA,AIZA,AFMA;ADIA,AKfA,ADGA,ALeA,AOrBA,AHSA,AFMA;ADIA,AKfA,ADGA,ALeA,AOrBA,AHSA,AFMA;ADIA,AKfA,ADGA,ALeA,AOrBA,AHSA,AFMA;AMjBA,APqBA,AKfA,ADGA,AENA,AHSA,AFMA;AMjBA,APqBA,AKfA,ADGA,AENA,ALeA;AMjBA,APqBA,AKfA,ADGA,AENA,ALeA;AMjBA,ACHA,ARwBA,AKfA,ADGA,AENA,ALeA;AMjBA,ACHA,ARwBA,AKfA,ADGA,AENA,ALeA;AMjBA,ACHA,ARwBA,AKfA,ADGA,AENA,ALeA;AMjBA,ACHA,ARwBA,AKfA,ADGA,AENA,ALeA,AQxBA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,ALeA,AQxBA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AIZA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AIZA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AIZA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AENA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,ADGA,ADGA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,AFMA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,AFMA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,AFMA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AKfA,AFMA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA,AGTA;AFOA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;ACFA,ACHA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA,ANkBA;AELA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AKfA,ADGA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AJaA,ARwBA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA,AQxBA;AZqCA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA,AIZA;AJaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["const { get } = require('./fetcher.js')\nconst GitFetcher = require('./git.js')\nconst RegistryFetcher = require('./registry.js')\nconst FileFetcher = require('./file.js')\nconst DirFetcher = require('./dir.js')\nconst RemoteFetcher = require('./remote.js')\n\nmodule.exports = {\n  GitFetcher,\n  RegistryFetcher,\n  FileFetcher,\n  DirFetcher,\n  RemoteFetcher,\n  resolve: (spec, opts) => get(spec, opts).resolve(),\n  extract: (spec, dest, opts) => get(spec, opts).extract(dest),\n  manifest: (spec, opts) => get(spec, opts).manifest(),\n  tarball: (spec, opts) => get(spec, opts).tarball(),\n  packument: (spec, opts) => get(spec, opts).packument(),\n}\nmodule.exports.tarball.stream = (spec, handler, opts) =>\n  get(spec, opts).tarballStream(handler)\nmodule.exports.tarball.file = (spec, dest, opts) =>\n  get(spec, opts).tarballFile(dest)\n","// This is the base class that the other fetcher types in lib\n// all descend from.\n// It handles the unpacking and retry logic that is shared among\n// all of the other Fetcher types.\n\nconst npa = require('npm-package-arg')\nconst ssri = require('ssri')\nconst { promisify } = require('util')\nconst { basename, dirname } = require('path')\nconst rimraf = promisify(require('rimraf'))\nconst tar = require('tar')\nconst log = require('proc-log')\nconst retry = require('promise-retry')\nconst fsm = require('fs-minipass')\nconst cacache = require('cacache')\nconst isPackageBin = require('./util/is-package-bin.js')\nconst removeTrailingSlashes = require('./util/trailing-slashes.js')\nconst getContents = require('@npmcli/installed-package-contents')\nconst readPackageJsonFast = require('read-package-json-fast')\nconst readPackageJson = promisify(require('read-package-json'))\n\n// we only change ownership on unix platforms, and only if uid is 0\nconst selfOwner = process.getuid && process.getuid() === 0 ? {\n  uid: 0,\n  gid: process.getgid(),\n} : null\nconst chownr = selfOwner ? promisify(require('chownr')) : null\nconst inferOwner = selfOwner ? require('infer-owner') : null\nconst mkdirp = require('mkdirp')\nconst cacheDir = require('./util/cache-dir.js')\n\n// Private methods.\n// Child classes should not have to override these.\n// Users should never call them.\nconst _chown = Symbol('_chown')\nconst _extract = Symbol('_extract')\nconst _mkdir = Symbol('_mkdir')\nconst _empty = Symbol('_empty')\nconst _toFile = Symbol('_toFile')\nconst _tarxOptions = Symbol('_tarxOptions')\nconst _entryMode = Symbol('_entryMode')\nconst _istream = Symbol('_istream')\nconst _assertType = Symbol('_assertType')\nconst _tarballFromCache = Symbol('_tarballFromCache')\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nconst _cacheFetches = Symbol.for('pacote.Fetcher._cacheFetches')\nconst _readPackageJson = Symbol.for('package.Fetcher._readPackageJson')\n\nclass FetcherBase {\n  constructor (spec, opts) {\n    if (!opts || typeof opts !== 'object') {\n      throw new TypeError('options object is required')\n    }\n    this.spec = npa(spec, opts.where)\n\n    this.allowGitIgnore = !!opts.allowGitIgnore\n\n    // a bit redundant because presumably the caller already knows this,\n    // but it makes it easier to not have to keep track of the requested\n    // spec when we're dispatching thousands of these at once, and normalizing\n    // is nice.  saveSpec is preferred if set, because it turns stuff like\n    // x/y#committish into github:x/y#committish.  use name@rawSpec for\n    // registry deps so that we turn xyz and xyz@ -> xyz@\n    this.from = this.spec.registry\n      ? `${this.spec.name}@${this.spec.rawSpec}` : this.spec.saveSpec\n\n    this[_assertType]()\n    // clone the opts object so that others aren't upset when we mutate it\n    // by adding/modifying the integrity value.\n    this.opts = { ...opts }\n\n    this.cache = opts.cache || cacheDir()\n    this.resolved = opts.resolved || null\n\n    // default to caching/verifying with sha512, that's what we usually have\n    // need to change this default, or start overriding it, when sha512\n    // is no longer strong enough.\n    this.defaultIntegrityAlgorithm = opts.defaultIntegrityAlgorithm || 'sha512'\n\n    if (typeof opts.integrity === 'string') {\n      this.opts.integrity = ssri.parse(opts.integrity)\n    }\n\n    this.package = null\n    this.type = this.constructor.name\n    this.fmode = opts.fmode || 0o666\n    this.dmode = opts.dmode || 0o777\n    // we don't need a default umask, because we don't chmod files coming\n    // out of package tarballs.  they're forced to have a mode that is\n    // valid, regardless of what's in the tarball entry, and then we let\n    // the process's umask setting do its job.  but if configured, we do\n    // respect it.\n    this.umask = opts.umask || 0\n\n    this.preferOnline = !!opts.preferOnline\n    this.preferOffline = !!opts.preferOffline\n    this.offline = !!opts.offline\n\n    this.before = opts.before\n    this.fullMetadata = this.before ? true : !!opts.fullMetadata\n    this.fullReadJson = !!opts.fullReadJson\n    if (this.fullReadJson) {\n      this[_readPackageJson] = readPackageJson\n    } else {\n      this[_readPackageJson] = readPackageJsonFast\n    }\n\n    this.defaultTag = opts.defaultTag || 'latest'\n    this.registry = removeTrailingSlashes(opts.registry || 'https://registry.npmjs.org')\n\n    // command to run 'prepare' scripts on directories and git dirs\n    // To use pacote with yarn, for example, set npmBin to 'yarn'\n    // and npmCliConfig with yarn's equivalents.\n    this.npmBin = opts.npmBin || 'npm'\n\n    // command to install deps for preparing\n    this.npmInstallCmd = opts.npmInstallCmd || ['install', '--force']\n\n    // XXX fill more of this in based on what we know from this.opts\n    // we explicitly DO NOT fill in --tag, though, since we are often\n    // going to be packing in the context of a publish, which may set\n    // a dist-tag, but certainly wants to keep defaulting to latest.\n    this.npmCliConfig = opts.npmCliConfig || [\n      `--cache=${dirname(this.cache)}`,\n      `--prefer-offline=${!!this.preferOffline}`,\n      `--prefer-online=${!!this.preferOnline}`,\n      `--offline=${!!this.offline}`,\n      ...(this.before ? [`--before=${this.before.toISOString()}`] : []),\n      '--no-progress',\n      '--no-save',\n      '--no-audit',\n      // override any omit settings from the environment\n      '--include=dev',\n      '--include=peer',\n      '--include=optional',\n      // we need the actual things, not just the lockfile\n      '--no-package-lock-only',\n      '--no-dry-run',\n    ]\n  }\n\n  get integrity () {\n    return this.opts.integrity || null\n  }\n\n  set integrity (i) {\n    if (!i) {\n      return\n    }\n\n    i = ssri.parse(i)\n    const current = this.opts.integrity\n\n    // do not ever update an existing hash value, but do\n    // merge in NEW algos and hashes that we don't already have.\n    if (current) {\n      current.merge(i)\n    } else {\n      this.opts.integrity = i\n    }\n  }\n\n  get notImplementedError () {\n    return new Error('not implemented in this fetcher type: ' + this.type)\n  }\n\n  // override in child classes\n  // Returns a Promise that resolves to this.resolved string value\n  resolve () {\n    return this.resolved ? Promise.resolve(this.resolved)\n      : Promise.reject(this.notImplementedError)\n  }\n\n  packument () {\n    return Promise.reject(this.notImplementedError)\n  }\n\n  // override in child class\n  // returns a manifest containing:\n  // - name\n  // - version\n  // - _resolved\n  // - _integrity\n  // - plus whatever else was in there (corgi, full metadata, or pj file)\n  manifest () {\n    return Promise.reject(this.notImplementedError)\n  }\n\n  // private, should be overridden.\n  // Note that they should *not* calculate or check integrity or cache,\n  // but *just*  return the raw tarball data stream.\n  [_tarballFromResolved] () {\n    throw this.notImplementedError\n  }\n\n  // public, should not be overridden\n  tarball () {\n    return this.tarballStream(stream => stream.concat().then(data => {\n      data.integrity = this.integrity && String(this.integrity)\n      data.resolved = this.resolved\n      data.from = this.from\n      return data\n    }))\n  }\n\n  // private\n  // Note: cacache will raise a EINTEGRITY error if the integrity doesn't match\n  [_tarballFromCache] () {\n    return cacache.get.stream.byDigest(this.cache, this.integrity, this.opts)\n  }\n\n  get [_cacheFetches] () {\n    return true\n  }\n\n  [_istream] (stream) {\n    // everyone will need one of these, either for verifying or calculating\n    // We always set it, because we have might only have a weak legacy hex\n    // sha1 in the packument, and this MAY upgrade it to a stronger algo.\n    // If we had an integrity, and it doesn't match, then this does not\n    // override that error; the istream will raise the error before it\n    // gets to the point of re-setting the integrity.\n    const istream = ssri.integrityStream(this.opts)\n    istream.on('integrity', i => this.integrity = i)\n    stream.on('error', er => istream.emit('error', er))\n\n    // if not caching this, just pipe through to the istream and return it\n    if (!this.opts.cache || !this[_cacheFetches]) {\n      return stream.pipe(istream)\n    }\n\n    // we have to return a stream that gets ALL the data, and proxies errors,\n    // but then pipe from the original tarball stream into the cache as well.\n    // To do this without losing any data, and since the cacache put stream\n    // is not a passthrough, we have to pipe from the original stream into\n    // the cache AFTER we pipe into the istream.  Since the cache stream\n    // has an asynchronous flush to write its contents to disk, we need to\n    // defer the istream end until the cache stream ends.\n    stream.pipe(istream, { end: false })\n    const cstream = cacache.put.stream(\n      this.opts.cache,\n      `pacote:tarball:${this.from}`,\n      this.opts\n    )\n    stream.pipe(cstream)\n    // defer istream end until after cstream\n    // cache write errors should not crash the fetch, this is best-effort.\n    cstream.promise().catch(() => {}).then(() => istream.end())\n\n    return istream\n  }\n\n  pickIntegrityAlgorithm () {\n    return this.integrity ? this.integrity.pickAlgorithm(this.opts)\n      : this.defaultIntegrityAlgorithm\n  }\n\n  // TODO: check error class, once those are rolled out to our deps\n  isDataCorruptionError (er) {\n    return er.code === 'EINTEGRITY' || er.code === 'Z_DATA_ERROR'\n  }\n\n  // override the types getter\n  get types () {}\n  [_assertType] () {\n    if (this.types && !this.types.includes(this.spec.type)) {\n      throw new TypeError(`Wrong spec type (${\n        this.spec.type\n      }) for ${\n        this.constructor.name\n      }. Supported types: ${this.types.join(', ')}`)\n    }\n  }\n\n  // We allow ENOENTs from cacache, but not anywhere else.\n  // An ENOENT trying to read a tgz file, for example, is Right Out.\n  isRetriableError (er) {\n    // TODO: check error class, once those are rolled out to our deps\n    return this.isDataCorruptionError(er) ||\n      er.code === 'ENOENT' ||\n      er.code === 'EISDIR'\n  }\n\n  // Mostly internal, but has some uses\n  // Pass in a function which returns a promise\n  // Function will be called 1 or more times with streams that may fail.\n  // Retries:\n  // Function MUST handle errors on the stream by rejecting the promise,\n  // so that retry logic can pick it up and either retry or fail whatever\n  // promise it was making (ie, failing extraction, etc.)\n  //\n  // The return value of this method is a Promise that resolves the same\n  // as whatever the streamHandler resolves to.\n  //\n  // This should never be overridden by child classes, but it is public.\n  tarballStream (streamHandler) {\n    // Only short-circuit via cache if we have everything else we'll need,\n    // and the user has not expressed a preference for checking online.\n\n    const fromCache = (\n      !this.preferOnline &&\n      this.integrity &&\n      this.resolved\n    ) ? streamHandler(this[_tarballFromCache]()).catch(er => {\n        if (this.isDataCorruptionError(er)) {\n          log.warn('tarball', `cached data for ${\n          this.spec\n        } (${this.integrity}) seems to be corrupted. Refreshing cache.`)\n          return this.cleanupCached().then(() => {\n            throw er\n          })\n        } else {\n          throw er\n        }\n      }) : null\n\n    const fromResolved = er => {\n      if (er) {\n        if (!this.isRetriableError(er)) {\n          throw er\n        }\n        log.silly('tarball', `no local data for ${\n          this.spec\n        }. Extracting by manifest.`)\n      }\n      return this.resolve().then(() => retry(tryAgain =>\n        streamHandler(this[_istream](this[_tarballFromResolved]()))\n          .catch(er => {\n          // Most likely data integrity.  A cache ENOENT error is unlikely\n          // here, since we're definitely not reading from the cache, but it\n          // IS possible that the fetch subsystem accessed the cache, and the\n          // entry got blown away or something.  Try one more time to be sure.\n            if (this.isRetriableError(er)) {\n              log.warn('tarball', `tarball data for ${\n              this.spec\n            } (${this.integrity}) seems to be corrupted. Trying again.`)\n              return this.cleanupCached().then(() => tryAgain(er))\n            }\n            throw er\n          }), { retries: 1, minTimeout: 0, maxTimeout: 0 }))\n    }\n\n    return fromCache ? fromCache.catch(fromResolved) : fromResolved()\n  }\n\n  cleanupCached () {\n    return cacache.rm.content(this.cache, this.integrity, this.opts)\n  }\n\n  async [_chown] (path, uid, gid) {\n    return selfOwner && (selfOwner.gid !== gid || selfOwner.uid !== uid)\n      ? chownr(path, uid, gid)\n      : /* istanbul ignore next - we don't test in root-owned folders */ null\n  }\n\n  [_empty] (path) {\n    return getContents({ path, depth: 1 }).then(contents => Promise.all(\n      contents.map(entry => rimraf(entry))))\n  }\n\n  [_mkdir] (dest) {\n    // if we're bothering to do owner inference, then do it.\n    // otherwise just make the dir, and return an empty object.\n    // always empty the dir dir to start with, but do so\n    // _after_ inferring the owner, in case there's an existing folder\n    // there that we would want to preserve which differs from the\n    // parent folder (rare, but probably happens sometimes).\n    return !inferOwner\n      ? this[_empty](dest).then(() => mkdirp(dest)).then(() => ({}))\n      : inferOwner(dest).then(({ uid, gid }) =>\n        this[_empty](dest)\n          .then(() => mkdirp(dest))\n          .then(made => {\n            // ignore the || dest part in coverage.  It's there to handle\n            // race conditions where the dir may be made by someone else\n            // after being removed by us.\n            const dir = made || /* istanbul ignore next */ dest\n            return this[_chown](dir, uid, gid)\n          })\n          .then(() => ({ uid, gid })))\n  }\n\n  // extraction is always the same.  the only difference is where\n  // the tarball comes from.\n  extract (dest) {\n    return this[_mkdir](dest).then(({ uid, gid }) =>\n      this.tarballStream(tarball => this[_extract](dest, tarball, uid, gid)))\n  }\n\n  [_toFile] (dest) {\n    return this.tarballStream(str => new Promise((res, rej) => {\n      const writer = new fsm.WriteStream(dest)\n      str.on('error', er => writer.emit('error', er))\n      writer.on('error', er => rej(er))\n      writer.on('close', () => res({\n        integrity: this.integrity && String(this.integrity),\n        resolved: this.resolved,\n        from: this.from,\n      }))\n      str.pipe(writer)\n    }))\n  }\n\n  // don't use this[_mkdir] because we don't want to rimraf anything\n  tarballFile (dest) {\n    const dir = dirname(dest)\n    return !inferOwner\n      ? mkdirp(dir).then(() => this[_toFile](dest))\n      : inferOwner(dest).then(({ uid, gid }) =>\n        mkdirp(dir).then(made => this[_toFile](dest)\n          .then(res => this[_chown](made || dir, uid, gid)\n            .then(() => res))))\n  }\n\n  [_extract] (dest, tarball, uid, gid) {\n    const extractor = tar.x(this[_tarxOptions]({ cwd: dest, uid, gid }))\n    const p = new Promise((resolve, reject) => {\n      extractor.on('end', () => {\n        resolve({\n          resolved: this.resolved,\n          integrity: this.integrity && String(this.integrity),\n          from: this.from,\n        })\n      })\n\n      extractor.on('error', er => {\n        log.warn('tar', er.message)\n        log.silly('tar', er)\n        reject(er)\n      })\n\n      tarball.on('error', er => reject(er))\n    })\n\n    tarball.pipe(extractor)\n    return p\n  }\n\n  // always ensure that entries are at least as permissive as our configured\n  // dmode/fmode, but never more permissive than the umask allows.\n  [_entryMode] (path, mode, type) {\n    const m = /Directory|GNUDumpDir/.test(type) ? this.dmode\n      : /File$/.test(type) ? this.fmode\n      : /* istanbul ignore next - should never happen in a pkg */ 0\n\n    // make sure package bins are executable\n    const exe = isPackageBin(this.package, path) ? 0o111 : 0\n    // always ensure that files are read/writable by the owner\n    return ((mode | m) & ~this.umask) | exe | 0o600\n  }\n\n  [_tarxOptions] ({ cwd, uid, gid }) {\n    const sawIgnores = new Set()\n    return {\n      cwd,\n      noChmod: true,\n      noMtime: true,\n      filter: (name, entry) => {\n        if (/Link$/.test(entry.type)) {\n          return false\n        }\n        entry.mode = this[_entryMode](entry.path, entry.mode, entry.type)\n        // this replicates the npm pack behavior where .gitignore files\n        // are treated like .npmignore files, but only if a .npmignore\n        // file is not present.\n        if (/File$/.test(entry.type)) {\n          const base = basename(entry.path)\n          if (base === '.npmignore') {\n            sawIgnores.add(entry.path)\n          } else if (base === '.gitignore' && !this.allowGitIgnore) {\n            // rename, but only if there's not already a .npmignore\n            const ni = entry.path.replace(/\\.gitignore$/, '.npmignore')\n            if (sawIgnores.has(ni)) {\n              return false\n            }\n            entry.path = ni\n          }\n          return true\n        }\n      },\n      strip: 1,\n      onwarn: /* istanbul ignore next - we can trust that tar logs */\n      (code, msg, data) => {\n        log.warn('tar', code, msg)\n        log.silly('tar', code, msg, data)\n      },\n      uid,\n      gid,\n      umask: this.umask,\n    }\n  }\n}\n\nmodule.exports = FetcherBase\n\n// Child classes\nconst GitFetcher = require('./git.js')\nconst RegistryFetcher = require('./registry.js')\nconst FileFetcher = require('./file.js')\nconst DirFetcher = require('./dir.js')\nconst RemoteFetcher = require('./remote.js')\n\n// Get an appropriate fetcher object from a spec and options\nFetcherBase.get = (rawSpec, opts = {}) => {\n  const spec = npa(rawSpec, opts.where)\n  switch (spec.type) {\n    case 'git':\n      return new GitFetcher(spec, opts)\n\n    case 'remote':\n      return new RemoteFetcher(spec, opts)\n\n    case 'version':\n    case 'range':\n    case 'tag':\n    case 'alias':\n      return new RegistryFetcher(spec.subSpec || spec, opts)\n\n    case 'file':\n      return new FileFetcher(spec, opts)\n\n    case 'directory':\n      return new DirFetcher(spec, opts)\n\n    default:\n      throw new TypeError('Unknown spec type: ' + spec.type)\n  }\n}\n","// Function to determine whether a path is in the package.bin set.\n// Used to prevent issues when people publish a package from a\n// windows machine, and then install with --no-bin-links.\n//\n// Note: this is not possible in remote or file fetchers, since\n// we don't have the manifest until AFTER we've unpacked.  But the\n// main use case is registry fetching with git a distant second,\n// so that's an acceptable edge case to not handle.\n\nconst binObj = (name, bin) =>\n  typeof bin === 'string' ? { [name]: bin } : bin\n\nconst hasBin = (pkg, path) => {\n  const bin = binObj(pkg.name, pkg.bin)\n  const p = path.replace(/^[^\\\\/]*\\//, '')\n  for (const kv of Object.entries(bin)) {\n    if (kv[1] === p) {\n      return true\n    }\n  }\n  return false\n}\n\nmodule.exports = (pkg, path) =>\n  pkg && pkg.bin ? hasBin(pkg, path) : false\n","const removeTrailingSlashes = (input) => {\n  // in order to avoid regexp redos detection\n  let output = input\n  while (output.endsWith('/')) {\n    output = output.substr(0, output.length - 1)\n  }\n  return output\n}\n\nmodule.exports = removeTrailingSlashes\n","const os = require('os')\nconst { resolve } = require('path')\n\nmodule.exports = (fakePlatform = false) => {\n  const temp = os.tmpdir()\n  const uidOrPid = process.getuid ? process.getuid() : process.pid\n  const home = os.homedir() || resolve(temp, 'npm-' + uidOrPid)\n  const platform = fakePlatform || process.platform\n  const cacheExtra = platform === 'win32' ? 'npm-cache' : '.npm'\n  const cacheRoot = (platform === 'win32' && process.env.LOCALAPPDATA) || home\n  return resolve(cacheRoot, cacheExtra, '_cacache')\n}\n","const Fetcher = require('./fetcher.js')\nconst FileFetcher = require('./file.js')\nconst RemoteFetcher = require('./remote.js')\nconst DirFetcher = require('./dir.js')\nconst hashre = /^[a-f0-9]{40}$/\nconst git = require('@npmcli/git')\nconst pickManifest = require('npm-pick-manifest')\nconst npa = require('npm-package-arg')\nconst Minipass = require('minipass')\nconst cacache = require('cacache')\nconst log = require('proc-log')\nconst npm = require('./util/npm.js')\n\nconst _resolvedFromRepo = Symbol('_resolvedFromRepo')\nconst _resolvedFromHosted = Symbol('_resolvedFromHosted')\nconst _resolvedFromClone = Symbol('_resolvedFromClone')\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nconst _addGitSha = Symbol('_addGitSha')\nconst addGitSha = require('./util/add-git-sha.js')\nconst _clone = Symbol('_clone')\nconst _cloneHosted = Symbol('_cloneHosted')\nconst _cloneRepo = Symbol('_cloneRepo')\nconst _setResolvedWithSha = Symbol('_setResolvedWithSha')\nconst _prepareDir = Symbol('_prepareDir')\nconst _readPackageJson = Symbol.for('package.Fetcher._readPackageJson')\n\n// get the repository url.\n// prefer https if there's auth, since ssh will drop that.\n// otherwise, prefer ssh if available (more secure).\n// We have to add the git+ back because npa suppresses it.\nconst repoUrl = (h, opts) =>\n  h.sshurl && !(h.https && h.auth) && addGitPlus(h.sshurl(opts)) ||\n  h.https && addGitPlus(h.https(opts))\n\n// add git+ to the url, but only one time.\nconst addGitPlus = url => url && `git+${url}`.replace(/^(git\\+)+/, 'git+')\n\nclass GitFetcher extends Fetcher {\n  constructor (spec, opts) {\n    super(spec, opts)\n\n    // we never want to compare integrity for git dependencies: npm/rfcs#525\n    if (this.opts.integrity) {\n      delete this.opts.integrity\n      log.warn(`skipping integrity check for git dependency ${this.spec.fetchSpec}`)\n    }\n\n    this.resolvedRef = null\n    if (this.spec.hosted) {\n      this.from = this.spec.hosted.shortcut({ noCommittish: false })\n    }\n\n    // shortcut: avoid full clone when we can go straight to the tgz\n    // if we have the full sha and it's a hosted git platform\n    if (this.spec.gitCommittish && hashre.test(this.spec.gitCommittish)) {\n      this.resolvedSha = this.spec.gitCommittish\n      // use hosted.tarball() when we shell to RemoteFetcher later\n      this.resolved = this.spec.hosted\n        ? repoUrl(this.spec.hosted, { noCommittish: false })\n        : this.spec.rawSpec\n    } else {\n      this.resolvedSha = ''\n    }\n  }\n\n  // just exposed to make it easier to test all the combinations\n  static repoUrl (hosted, opts) {\n    return repoUrl(hosted, opts)\n  }\n\n  get types () {\n    return ['git']\n  }\n\n  resolve () {\n    // likely a hosted git repo with a sha, so get the tarball url\n    // but in general, no reason to resolve() more than necessary!\n    if (this.resolved) {\n      return super.resolve()\n    }\n\n    // fetch the git repo and then look at the current hash\n    const h = this.spec.hosted\n    // try to use ssh, fall back to git.\n    return h ? this[_resolvedFromHosted](h)\n      : this[_resolvedFromRepo](this.spec.fetchSpec)\n  }\n\n  // first try https, since that's faster and passphrase-less for\n  // public repos, and supports private repos when auth is provided.\n  // Fall back to SSH to support private repos\n  // NB: we always store the https url in resolved field if auth\n  // is present, otherwise ssh if the hosted type provides it\n  [_resolvedFromHosted] (hosted) {\n    return this[_resolvedFromRepo](hosted.https && hosted.https())\n      .catch(er => {\n        // Throw early since we know pathspec errors will fail again if retried\n        if (er instanceof git.errors.GitPathspecError) {\n          throw er\n        }\n        const ssh = hosted.sshurl && hosted.sshurl()\n        // no fallthrough if we can't fall through or have https auth\n        if (!ssh || hosted.auth) {\n          throw er\n        }\n        return this[_resolvedFromRepo](ssh)\n      })\n  }\n\n  [_resolvedFromRepo] (gitRemote) {\n    // XXX make this a custom error class\n    if (!gitRemote) {\n      return Promise.reject(new Error(`No git url for ${this.spec}`))\n    }\n    const gitRange = this.spec.gitRange\n    const name = this.spec.name\n    return git.revs(gitRemote, this.opts).then(remoteRefs => {\n      return gitRange ? pickManifest({\n        versions: remoteRefs.versions,\n        'dist-tags': remoteRefs['dist-tags'],\n        name,\n      }, gitRange, this.opts)\n        : this.spec.gitCommittish ?\n          remoteRefs.refs[this.spec.gitCommittish] ||\n          remoteRefs.refs[remoteRefs.shas[this.spec.gitCommittish]]\n          : remoteRefs.refs.HEAD // no git committish, get default head\n    }).then(revDoc => {\n      // the committish provided isn't in the rev list\n      // things like HEAD~3 or @yesterday can land here.\n      if (!revDoc || !revDoc.sha) {\n        return this[_resolvedFromClone]()\n      }\n\n      this.resolvedRef = revDoc\n      this.resolvedSha = revDoc.sha\n      this[_addGitSha](revDoc.sha)\n      return this.resolved\n    })\n  }\n\n  [_setResolvedWithSha] (withSha) {\n    // we haven't cloned, so a tgz download is still faster\n    // of course, if it's not a known host, we can't do that.\n    this.resolved = !this.spec.hosted ? withSha\n      : repoUrl(npa(withSha).hosted, { noCommittish: false })\n  }\n\n  // when we get the git sha, we affix it to our spec to build up\n  // either a git url with a hash, or a tarball download URL\n  [_addGitSha] (sha) {\n    this[_setResolvedWithSha](addGitSha(this.spec, sha))\n  }\n\n  [_resolvedFromClone] () {\n    // do a full or shallow clone, then look at the HEAD\n    // kind of wasteful, but no other option, really\n    return this[_clone](dir => this.resolved)\n  }\n\n  [_prepareDir] (dir) {\n    return this[_readPackageJson](dir + '/package.json').then(mani => {\n      // no need if we aren't going to do any preparation.\n      const scripts = mani.scripts\n      if (!mani.workspaces && (!scripts || !(\n        scripts.postinstall ||\n          scripts.build ||\n          scripts.preinstall ||\n          scripts.install ||\n          scripts.prepack ||\n          scripts.prepare))) {\n        return\n      }\n\n      // to avoid cases where we have an cycle of git deps that depend\n      // on one another, we only ever do preparation for one instance\n      // of a given git dep along the chain of installations.\n      // Note that this does mean that a dependency MAY in theory end up\n      // trying to run its prepare script using a dependency that has not\n      // been properly prepared itself, but that edge case is smaller\n      // and less hazardous than a fork bomb of npm and git commands.\n      const noPrepare = !process.env._PACOTE_NO_PREPARE_ ? []\n        : process.env._PACOTE_NO_PREPARE_.split('\\n')\n      if (noPrepare.includes(this.resolved)) {\n        log.info('prepare', 'skip prepare, already seen', this.resolved)\n        return\n      }\n      noPrepare.push(this.resolved)\n\n      // the DirFetcher will do its own preparation to run the prepare scripts\n      // All we have to do is put the deps in place so that it can succeed.\n      return npm(\n        this.npmBin,\n        [].concat(this.npmInstallCmd).concat(this.npmCliConfig),\n        dir,\n        { ...process.env, _PACOTE_NO_PREPARE_: noPrepare.join('\\n') },\n        { message: 'git dep preparation failed' }\n      )\n    })\n  }\n\n  [_tarballFromResolved] () {\n    const stream = new Minipass()\n    stream.resolved = this.resolved\n    stream.from = this.from\n\n    // check it out and then shell out to the DirFetcher tarball packer\n    this[_clone](dir => this[_prepareDir](dir)\n      .then(() => new Promise((res, rej) => {\n        const df = new DirFetcher(`file:${dir}`, {\n          ...this.opts,\n          resolved: null,\n          integrity: null,\n        })\n        const dirStream = df[_tarballFromResolved]()\n        dirStream.on('error', rej)\n        dirStream.on('end', res)\n        dirStream.pipe(stream)\n      }))).catch(\n      /* istanbul ignore next: very unlikely and hard to test */\n      er => stream.emit('error', er)\n    )\n    return stream\n  }\n\n  // clone a git repo into a temp folder (or fetch and unpack if possible)\n  // handler accepts a directory, and returns a promise that resolves\n  // when we're done with it, at which point, cacache deletes it\n  //\n  // TODO: after cloning, create a tarball of the folder, and add to the cache\n  // with cacache.put.stream(), using a key that's deterministic based on the\n  // spec and repo, so that we don't ever clone the same thing multiple times.\n  [_clone] (handler, tarballOk = true) {\n    const o = { tmpPrefix: 'git-clone' }\n    const ref = this.resolvedSha || this.spec.gitCommittish\n    const h = this.spec.hosted\n    const resolved = this.resolved\n\n    // can be set manually to false to fall back to actual git clone\n    tarballOk = tarballOk &&\n      h && resolved === repoUrl(h, { noCommittish: false }) && h.tarball\n\n    return cacache.tmp.withTmp(this.cache, o, tmp => {\n      // if we're resolved, and have a tarball url, shell out to RemoteFetcher\n      if (tarballOk) {\n        const nameat = this.spec.name ? `${this.spec.name}@` : ''\n        return new RemoteFetcher(h.tarball({ noCommittish: false }), {\n          ...this.opts,\n          allowGitIgnore: true,\n          pkgid: `git:${nameat}${this.resolved}`,\n          resolved: this.resolved,\n          integrity: null, // it'll always be different, if we have one\n        }).extract(tmp).then(() => handler(tmp), er => {\n          // fall back to ssh download if tarball fails\n          if (er.constructor.name.match(/^Http/)) {\n            return this[_clone](handler, false)\n          } else {\n            throw er\n          }\n        })\n      }\n\n      return (\n        h ? this[_cloneHosted](ref, tmp)\n        : this[_cloneRepo](this.spec.fetchSpec, ref, tmp)\n      ).then(sha => {\n        this.resolvedSha = sha\n        if (!this.resolved) {\n          this[_addGitSha](sha)\n        }\n      })\n        .then(() => handler(tmp))\n    })\n  }\n\n  // first try https, since that's faster and passphrase-less for\n  // public repos, and supports private repos when auth is provided.\n  // Fall back to SSH to support private repos\n  // NB: we always store the https url in resolved field if auth\n  // is present, otherwise ssh if the hosted type provides it\n  [_cloneHosted] (ref, tmp) {\n    const hosted = this.spec.hosted\n    return this[_cloneRepo](hosted.https({ noCommittish: true }), ref, tmp)\n      .catch(er => {\n        // Throw early since we know pathspec errors will fail again if retried\n        if (er instanceof git.errors.GitPathspecError) {\n          throw er\n        }\n        const ssh = hosted.sshurl && hosted.sshurl({ noCommittish: true })\n        // no fallthrough if we can't fall through or have https auth\n        if (!ssh || hosted.auth) {\n          throw er\n        }\n        return this[_cloneRepo](ssh, ref, tmp)\n      })\n  }\n\n  [_cloneRepo] (repo, ref, tmp) {\n    const { opts, spec } = this\n    return git.clone(repo, ref, tmp, { ...opts, spec })\n  }\n\n  manifest () {\n    if (this.package) {\n      return Promise.resolve(this.package)\n    }\n\n    return this.spec.hosted && this.resolved\n      ? FileFetcher.prototype.manifest.apply(this)\n      : this[_clone](dir =>\n        this[_readPackageJson](dir + '/package.json')\n          .then(mani => this.package = {\n            ...mani,\n            _resolved: this.resolved,\n            _from: this.from,\n          }))\n  }\n\n  packument () {\n    return FileFetcher.prototype.packument.apply(this)\n  }\n}\nmodule.exports = GitFetcher\n","const Fetcher = require('./fetcher.js')\nconst fsm = require('fs-minipass')\nconst cacache = require('cacache')\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nconst _exeBins = Symbol('_exeBins')\nconst { resolve } = require('path')\nconst fs = require('fs')\nconst _readPackageJson = Symbol.for('package.Fetcher._readPackageJson')\n\nclass FileFetcher extends Fetcher {\n  constructor (spec, opts) {\n    super(spec, opts)\n    // just the fully resolved filename\n    this.resolved = this.spec.fetchSpec\n  }\n\n  get types () {\n    return ['file']\n  }\n\n  manifest () {\n    if (this.package) {\n      return Promise.resolve(this.package)\n    }\n\n    // have to unpack the tarball for this.\n    return cacache.tmp.withTmp(this.cache, this.opts, dir =>\n      this.extract(dir)\n        .then(() => this[_readPackageJson](dir + '/package.json'))\n        .then(mani => this.package = {\n          ...mani,\n          _integrity: this.integrity && String(this.integrity),\n          _resolved: this.resolved,\n          _from: this.from,\n        }))\n  }\n\n  [_exeBins] (pkg, dest) {\n    if (!pkg.bin) {\n      return Promise.resolve()\n    }\n\n    return Promise.all(Object.keys(pkg.bin).map(k => new Promise(res => {\n      const script = resolve(dest, pkg.bin[k])\n      // Best effort.  Ignore errors here, the only result is that\n      // a bin script is not executable.  But if it's missing or\n      // something, we just leave it for a later stage to trip over\n      // when we can provide a more useful contextual error.\n      fs.stat(script, (er, st) => {\n        if (er) {\n          return res()\n        }\n        const mode = st.mode | 0o111\n        if (mode === st.mode) {\n          return res()\n        }\n        fs.chmod(script, mode, res)\n      })\n    })))\n  }\n\n  extract (dest) {\n    // if we've already loaded the manifest, then the super got it.\n    // but if not, read the unpacked manifest and chmod properly.\n    return super.extract(dest)\n      .then(result => this.package ? result\n      : this[_readPackageJson](dest + '/package.json').then(pkg =>\n        this[_exeBins](pkg, dest)).then(() => result))\n  }\n\n  [_tarballFromResolved] () {\n    // create a read stream and return it\n    return new fsm.ReadStream(this.resolved)\n  }\n\n  packument () {\n    // simulate based on manifest\n    return this.manifest().then(mani => ({\n      name: mani.name,\n      'dist-tags': {\n        [this.defaultTag]: mani.version,\n      },\n      versions: {\n        [mani.version]: {\n          ...mani,\n          dist: {\n            tarball: `file:${this.resolved}`,\n            integrity: this.integrity && String(this.integrity),\n          },\n        },\n      },\n    }))\n  }\n}\n\nmodule.exports = FileFetcher\n","const Fetcher = require('./fetcher.js')\nconst FileFetcher = require('./file.js')\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nconst pacoteVersion = require('../package.json').version\nconst fetch = require('npm-registry-fetch')\nconst Minipass = require('minipass')\n// The default registry URL is a string of great magic.\nconst magic = /^https?:\\/\\/registry\\.npmjs\\.org\\//\n\nconst _cacheFetches = Symbol.for('pacote.Fetcher._cacheFetches')\nconst _headers = Symbol('_headers')\nclass RemoteFetcher extends Fetcher {\n  constructor (spec, opts) {\n    super(spec, opts)\n    this.resolved = this.spec.fetchSpec\n    if (magic.test(this.resolved) && !magic.test(this.registry + '/')) {\n      this.resolved = this.resolved.replace(magic, this.registry + '/')\n    }\n\n    // nam is a fermented pork sausage that is good to eat\n    const nameat = this.spec.name ? `${this.spec.name}@` : ''\n    this.pkgid = opts.pkgid ? opts.pkgid : `remote:${nameat}${this.resolved}`\n  }\n\n  // Don't need to cache tarball fetches in pacote, because make-fetch-happen\n  // will write into cacache anyway.\n  get [_cacheFetches] () {\n    return false\n  }\n\n  [_tarballFromResolved] () {\n    const stream = new Minipass()\n    const fetchOpts = {\n      ...this.opts,\n      headers: this[_headers](),\n      spec: this.spec,\n      integrity: this.integrity,\n      algorithms: [this.pickIntegrityAlgorithm()],\n    }\n    fetch(this.resolved, fetchOpts).then(res => {\n      const hash = res.headers.get('x-local-cache-hash')\n      if (hash) {\n        this.integrity = decodeURIComponent(hash)\n      }\n\n      res.body.on('error',\n        /* istanbul ignore next - exceedingly rare and hard to simulate */\n        er => stream.emit('error', er)\n      ).pipe(stream)\n    }).catch(er => stream.emit('error', er))\n\n    return stream\n  }\n\n  [_headers] () {\n    return {\n      // npm will override this, but ensure that we always send *something*\n      'user-agent': this.opts.userAgent ||\n        `pacote/${pacoteVersion} node/${process.version}`,\n      ...(this.opts.headers || {}),\n      'pacote-version': pacoteVersion,\n      'pacote-req-type': 'tarball',\n      'pacote-pkg-id': this.pkgid,\n      ...(this.integrity ? { 'pacote-integrity': String(this.integrity) }\n      : {}),\n      ...(this.opts.headers || {}),\n    }\n  }\n\n  get types () {\n    return ['remote']\n  }\n\n  // getting a packument and/or manifest is the same as with a file: spec.\n  // unpack the tarball stream, and then read from the package.json file.\n  packument () {\n    return FileFetcher.prototype.packument.apply(this)\n  }\n\n  manifest () {\n    return FileFetcher.prototype.manifest.apply(this)\n  }\n}\nmodule.exports = RemoteFetcher\n","module.exports = {\n  \"name\": \"pacote\",\n  \"version\": \"13.0.5\",\n  \"description\": \"JavaScript package downloader\",\n  \"author\": \"GitHub Inc.\",\n  \"bin\": {\n    \"pacote\": \"lib/bin.js\"\n  },\n  \"license\": \"ISC\",\n  \"main\": \"lib/index.js\",\n  \"scripts\": {\n    \"test\": \"tap\",\n    \"snap\": \"tap\",\n    \"preversion\": \"npm test\",\n    \"postversion\": \"npm publish\",\n    \"prepublishOnly\": \"git push origin --follow-tags\",\n    \"lint\": \"eslint '**/*.js'\",\n    \"postlint\": \"npm-template-check\",\n    \"lintfix\": \"npm run lint -- --fix\",\n    \"posttest\": \"npm run lint\",\n    \"template-copy\": \"npm-template-copy --force\"\n  },\n  \"tap\": {\n    \"timeout\": 300,\n    \"coverage-map\": \"map.js\"\n  },\n  \"devDependencies\": {\n    \"@npmcli/template-oss\": \"^2.9.2\",\n    \"mutate-fs\": \"^2.1.1\",\n    \"npm-registry-mock\": \"^1.3.1\",\n    \"tap\": \"^15.1.6\"\n  },\n  \"files\": [\n    \"bin\",\n    \"lib\"\n  ],\n  \"keywords\": [\n    \"packages\",\n    \"npm\",\n    \"git\"\n  ],\n  \"dependencies\": {\n    \"@npmcli/git\": \"^3.0.0\",\n    \"@npmcli/installed-package-contents\": \"^1.0.7\",\n    \"@npmcli/promise-spawn\": \"^1.2.0\",\n    \"@npmcli/run-script\": \"^3.0.1\",\n    \"cacache\": \"^16.0.0\",\n    \"chownr\": \"^2.0.0\",\n    \"fs-minipass\": \"^2.1.0\",\n    \"infer-owner\": \"^1.0.4\",\n    \"minipass\": \"^3.1.6\",\n    \"mkdirp\": \"^1.0.4\",\n    \"npm-package-arg\": \"^9.0.0\",\n    \"npm-packlist\": \"^4.0.0\",\n    \"npm-pick-manifest\": \"^7.0.0\",\n    \"npm-registry-fetch\": \"^13.0.1\",\n    \"proc-log\": \"^2.0.0\",\n    \"promise-retry\": \"^2.0.1\",\n    \"read-package-json\": \"^5.0.0\",\n    \"read-package-json-fast\": \"^2.0.3\",\n    \"rimraf\": \"^3.0.2\",\n    \"ssri\": \"^8.0.1\",\n    \"tar\": \"^6.1.11\"\n  },\n  \"engines\": {\n    \"node\": \"^12.13.0 || ^14.15.0 || >=16\"\n  },\n  \"repository\": \"git@github.com:npm/pacote\",\n  \"templateOSS\": {\n    \"version\": \"2.9.2\",\n    \"windowsCI\": false\n  }\n}\n","const Fetcher = require('./fetcher.js')\nconst FileFetcher = require('./file.js')\nconst Minipass = require('minipass')\nconst tarCreateOptions = require('./util/tar-create-options.js')\nconst packlist = require('npm-packlist')\nconst tar = require('tar')\nconst _prepareDir = Symbol('_prepareDir')\nconst { resolve } = require('path')\nconst _readPackageJson = Symbol.for('package.Fetcher._readPackageJson')\n\nconst runScript = require('@npmcli/run-script')\n\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nclass DirFetcher extends Fetcher {\n  constructor (spec, opts) {\n    super(spec, opts)\n    // just the fully resolved filename\n    this.resolved = this.spec.fetchSpec\n  }\n\n  // exposes tarCreateOptions as public API\n  static tarCreateOptions (manifest) {\n    return tarCreateOptions(manifest)\n  }\n\n  get types () {\n    return ['directory']\n  }\n\n  [_prepareDir] () {\n    return this.manifest().then(mani => {\n      if (!mani.scripts || !mani.scripts.prepare) {\n        return\n      }\n\n      // we *only* run prepare.\n      // pre/post-pack is run by the npm CLI for publish and pack,\n      // but this function is *also* run when installing git deps\n      const stdio = this.opts.foregroundScripts ? 'inherit' : 'pipe'\n\n      // hide the banner if silent opt is passed in, or if prepare running\n      // in the background.\n      const banner = this.opts.silent ? false : stdio === 'inherit'\n\n      return runScript({\n        pkg: mani,\n        event: 'prepare',\n        path: this.resolved,\n        stdioString: true,\n        stdio,\n        banner,\n        env: {\n          npm_package_resolved: this.resolved,\n          npm_package_integrity: this.integrity,\n          npm_package_json: resolve(this.resolved, 'package.json'),\n        },\n      })\n    })\n  }\n\n  [_tarballFromResolved] () {\n    const stream = new Minipass()\n    stream.resolved = this.resolved\n    stream.integrity = this.integrity\n\n    // run the prepare script, get the list of files, and tar it up\n    // pipe to the stream, and proxy errors the chain.\n    this[_prepareDir]()\n      .then(() => packlist({ path: this.resolved }))\n      .then(files => tar.c(tarCreateOptions(this.package), files)\n        .on('error', er => stream.emit('error', er)).pipe(stream))\n      .catch(er => stream.emit('error', er))\n    return stream\n  }\n\n  manifest () {\n    if (this.package) {\n      return Promise.resolve(this.package)\n    }\n\n    return this[_readPackageJson](this.resolved + '/package.json')\n      .then(mani => this.package = {\n        ...mani,\n        _integrity: this.integrity && String(this.integrity),\n        _resolved: this.resolved,\n        _from: this.from,\n      })\n  }\n\n  packument () {\n    return FileFetcher.prototype.packument.apply(this)\n  }\n}\nmodule.exports = DirFetcher\n","const isPackageBin = require('./is-package-bin.js')\n\nconst tarCreateOptions = manifest => ({\n  cwd: manifest._resolved,\n  prefix: 'package/',\n  portable: true,\n  gzip: {\n    // forcing the level to 9 seems to avoid some\n    // platform specific optimizations that cause\n    // integrity mismatch errors due to differing\n    // end results after compression\n    level: 9,\n  },\n\n  // ensure that package bins are always executable\n  // Note that npm-packlist is already filtering out\n  // anything that is not a regular file, ignored by\n  // .npmignore or package.json \"files\", etc.\n  filter: (path, stat) => {\n    if (isPackageBin(manifest, path)) {\n      stat.mode |= 0o111\n    }\n    return true\n  },\n\n  // Provide a specific date in the 1980s for the benefit of zip,\n  // which is confounded by files dated at the Unix epoch 0.\n  mtime: new Date('1985-10-26T08:15:00.000Z'),\n})\n\nmodule.exports = tarCreateOptions\n","// run an npm command\nconst spawn = require('@npmcli/promise-spawn')\n\nmodule.exports = (npmBin, npmCommand, cwd, env, extra) => {\n  const isJS = npmBin.endsWith('.js')\n  const cmd = isJS ? process.execPath : npmBin\n  const args = (isJS ? [npmBin] : []).concat(npmCommand)\n  // when installing to run the `prepare` script for a git dep, we need\n  // to ensure that we don't run into a cycle of checking out packages\n  // in temp directories.  this lets us link previously-seen repos that\n  // are also being prepared.\n\n  return spawn(cmd, args, { cwd, stdioString: true, env }, extra)\n}\n","// add a sha to a git remote url spec\nconst addGitSha = (spec, sha) => {\n  if (spec.hosted) {\n    const h = spec.hosted\n    const opt = { noCommittish: true }\n    const base = h.https && h.auth ? h.https(opt) : h.shortcut(opt)\n\n    return `${base}#${sha}`\n  } else {\n    // don't use new URL for this, because it doesn't handle scp urls\n    return spec.rawSpec.replace(/#.*$/, '') + `#${sha}`\n  }\n}\n\nmodule.exports = addGitSha\n","const Fetcher = require('./fetcher.js')\nconst RemoteFetcher = require('./remote.js')\nconst _tarballFromResolved = Symbol.for('pacote.Fetcher._tarballFromResolved')\nconst pacoteVersion = require('../package.json').version\nconst removeTrailingSlashes = require('./util/trailing-slashes.js')\nconst npa = require('npm-package-arg')\nconst rpj = require('read-package-json-fast')\nconst pickManifest = require('npm-pick-manifest')\nconst ssri = require('ssri')\n\n// Corgis are cute. \nconst corgiDoc = 'application/vnd.npm.install-v1+json; q=1.0, application/json; q=0.8, */*'\nconst fullDoc = 'application/json'\n\nconst fetch = require('npm-registry-fetch')\n\n// TODO: memoize reg requests, so we don't even have to check cache\n\nconst _headers = Symbol('_headers')\nclass RegistryFetcher extends Fetcher {\n  constructor (spec, opts) {\n    super(spec, opts)\n\n    // you usually don't want to fetch the same packument multiple times in\n    // the span of a given script or command, no matter how many pacote calls\n    // are made, so this lets us avoid doing that.  It's only relevant for\n    // registry fetchers, because other types simulate their packument from\n    // the manifest, which they memoize on this.package, so it's very cheap\n    // already.\n    this.packumentCache = this.opts.packumentCache || null\n\n    // handle case when npm-package-arg guesses wrong.\n    if (this.spec.type === 'tag' &&\n        this.spec.rawSpec === '' &&\n        this.defaultTag !== 'latest') {\n      this.spec = npa(`${this.spec.name}@${this.defaultTag}`)\n    }\n    this.registry = fetch.pickRegistry(spec, opts)\n    this.packumentUrl = removeTrailingSlashes(this.registry) + '/' +\n      this.spec.escapedName\n\n    // XXX pacote <=9 has some logic to ignore opts.resolved if\n    // the resolved URL doesn't go to the same registry.\n    // Consider reproducing that here, to throw away this.resolved\n    // in that case.\n  }\n\n  resolve () {\n    if (this.resolved) {\n      return Promise.resolve(this.resolved)\n    }\n\n    // fetching the manifest sets resolved and (usually) integrity\n    return this.manifest().then(() => {\n      if (this.resolved) {\n        return this.resolved\n      }\n\n      throw Object.assign(\n        new Error('Invalid package manifest: no `dist.tarball` field'),\n        { package: this.spec.toString() }\n      )\n    })\n  }\n\n  [_headers] () {\n    return {\n      // npm will override UA, but ensure that we always send *something*\n      'user-agent': this.opts.userAgent ||\n        `pacote/${pacoteVersion} node/${process.version}`,\n      ...(this.opts.headers || {}),\n      'pacote-version': pacoteVersion,\n      'pacote-req-type': 'packument',\n      'pacote-pkg-id': `registry:${this.spec.name}`,\n      accept: this.fullMetadata ? fullDoc : corgiDoc,\n    }\n  }\n\n  async packument () {\n    // note this might be either an in-flight promise for a request,\n    // or the actual packument, but we never want to make more than\n    // one request at a time for the same thing regardless.\n    if (this.packumentCache && this.packumentCache.has(this.packumentUrl)) {\n      return this.packumentCache.get(this.packumentUrl)\n    }\n\n    // npm-registry-fetch the packument\n    // set the appropriate header for corgis if fullMetadata isn't set\n    // return the res.json() promise\n    const p = fetch(this.packumentUrl, {\n      ...this.opts,\n      headers: this[_headers](),\n      spec: this.spec,\n      // never check integrity for packuments themselves\n      integrity: null,\n    }).then(res => res.json().then(packument => {\n      packument._cached = res.headers.has('x-local-cache')\n      packument._contentLength = +res.headers.get('content-length')\n      if (this.packumentCache) {\n        this.packumentCache.set(this.packumentUrl, packument)\n      }\n      return packument\n    })).catch(er => {\n      if (this.packumentCache) {\n        this.packumentCache.delete(this.packumentUrl)\n      }\n      if (er.code === 'E404' && !this.fullMetadata) {\n        // possible that corgis are not supported by this registry\n        this.fullMetadata = true\n        return this.packument()\n      }\n      throw er\n    })\n    if (this.packumentCache) {\n      this.packumentCache.set(this.packumentUrl, p)\n    }\n    return p\n  }\n\n  manifest () {\n    if (this.package) {\n      return Promise.resolve(this.package)\n    }\n\n    return this.packument()\n      .then(packument => pickManifest(packument, this.spec.fetchSpec, {\n        ...this.opts,\n        defaultTag: this.defaultTag,\n        before: this.before,\n      }) /* XXX add ETARGET and E403 revalidation of cached packuments here */)\n      .then(mani => {\n        // add _resolved and _integrity from dist object\n        const { dist } = mani\n        if (dist) {\n          this.resolved = mani._resolved = dist.tarball\n          mani._from = this.from\n          const distIntegrity = dist.integrity ? ssri.parse(dist.integrity)\n            : dist.shasum ? ssri.fromHex(dist.shasum, 'sha1', { ...this.opts })\n            : null\n          if (distIntegrity) {\n            if (!this.integrity) {\n              this.integrity = distIntegrity\n            } else if (!this.integrity.match(distIntegrity)) {\n              // only bork if they have algos in common.\n              // otherwise we end up breaking if we have saved a sha512\n              // previously for the tarball, but the manifest only\n              // provides a sha1, which is possible for older publishes.\n              // Otherwise, this is almost certainly a case of holding it\n              // wrong, and will result in weird or insecure behavior\n              // later on when building package tree.\n              for (const algo of Object.keys(this.integrity)) {\n                if (distIntegrity[algo]) {\n                  throw Object.assign(new Error(\n                    `Integrity checksum failed when using ${algo}: ` +\n                    `wanted ${this.integrity} but got ${distIntegrity}.`\n                  ), { code: 'EINTEGRITY' })\n                }\n              }\n              // made it this far, the integrity is worthwhile.  accept it.\n              // the setter here will take care of merging it into what we\n              // already had.\n              this.integrity = distIntegrity\n            }\n          }\n        }\n        if (this.integrity) {\n          mani._integrity = String(this.integrity)\n        }\n        this.package = rpj.normalize(mani)\n        return this.package\n      })\n  }\n\n  [_tarballFromResolved] () {\n    // we use a RemoteFetcher to get the actual tarball stream\n    return new RemoteFetcher(this.resolved, {\n      ...this.opts,\n      resolved: this.resolved,\n      pkgid: `registry:${this.spec.name}@${this.resolved}`,\n    })[_tarballFromResolved]()\n  }\n\n  get types () {\n    return [\n      'tag',\n      'version',\n      'range',\n    ]\n  }\n}\nmodule.exports = RegistryFetcher\n"]}